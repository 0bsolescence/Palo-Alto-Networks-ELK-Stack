input {
  file {
        path => ["/var/log/traffic.log"]
        sincedb_path => "/var/log/logstash/sincedb"
        start_position => "beginning"
        type => "syslog"
        tags => ["traffic"]
        }
}

filter {
  if [type] == "syslog" {
    grok {
      # strips timestamp and host off of the front of the syslog message leaving the raw message generated by the syslog client and saves it as "raw_message"
      # patterns_dir => "/opt/logstash/patterns"
      match => [ "message", "%{TIMESTAMP_ISO8601:@timestamp} %{HOSTNAME:syslog_host} %{GREEDYDATA:raw_message}" ]
    }
  }

    csv {
      source => "raw_message"
      columns => [ "PaloAltoNetworksDomain","ReceiveTime","SerialNumber","Type","Subtype","FUTURE_USE","GeneratedTime","SourceIP","DestinationIP","NATSourceIP","NATDestinationIP","RuleName","SourceUser","DestinationUser","Application","VirtualSystem","SourceZone","DestinationZone","IngressInterface","EgressInterface","LogForwardingProfile","TimeLogged","SessionID","RepeatCount","SourcePort","DestinationPort","NATSourcePort","NATDestinationPort","Flags","Protocol","Action","Bytes","BytesSent","BytesReceived","Packets","StartTime","ElapsedTime","URLCategory","FUTURE_USE","SequenceNumber","ActionFlags","SourceLocation","DestinationLocation","FUTURE_USE","PacketsSent","PacketsReceived","SessionEndReason","DeviceGroupHierarchyLevel1","DeviceGroupHierarchyLevel2","DeviceGroupHierarchyLevel3","DeviceGroupHierarchyLevel4","VirtualSystemName","DeviceName","ActionSource" ]
    }
    date {
      timezone => "America/New_York"
      match => [ "GenerateTime", "YYYY/MM/dd HH:mm:ss" ]
    }
    # convert fields to proper format
    mutate {
      convert => [ "Bytes", "integer" ]
      convert => [ "BytesReceived", "integer" ]
      convert => [ "BytesSent", "integer" ]
      convert => [ "ElapsedTimeInSec", "integer" ]
      convert => [ "geoip.area_code", "integer" ]
      convert => [ "geoip.dma_code", "integer" ]
      convert => [ "geoip.latitude", "float" ]
      convert => [ "geoip.longitude", "float" ]
      convert => [ "NATDestinationPort", "integer" ]
      convert => [ "NATSourcePort", "integer" ]
      convert => [ "Packets", "integer" ]
      convert => [ "pkts_received", "integer" ]
      convert => [ "pkts_sent", "integer" ]
      convert => [ "seqno", "integer" ]
#      gsub => [ "Rule", " ", "_",
#                "Application", "( |-)", "_" ]
      remove_field => [ "message", "raw_message" ]
    }

  # Geolocate logs that have SourceIP if that SourceIP is a non-RFC1918 address
  if [SourceIP] and [SourceIP] !~ "(^127\.0\.0\.1)|(^10\.)|(^172\.1[6-9]\.)|(^172\.2[0-9]\.)|(^172\.3[0-1]\.)|(^192\.168\.)|(^169\.254\.)" {
      geoip {
           database => "/opt/logstash/GeoLite2-City.mmdb"
           source => "SourceIP"
           target => "SourceIPGeo"
      }
      # Delete 0,0 in SourceIPGeo.location if equal to 0,0
      if ([SourceIPGeo.location] and [SourceIPGeo.location] =~ "0,0") {
        mutate {
          replace => [ "SourceIPGeo.location", "" ]
        }
      }
    }

  # Geolocate logs that have DestinationIP and if that DestinationAddress is a non-RFC1918 address
  if [DestinationIP] and [DestinationIP] !~ "(^127\.0\.0\.1)|(^10\.)|(^172\.1[6-9]\.)|(^172\.2[0-9]\.)|(^172\.3[0-1]\.)|(^192\.168\.)|(^169\.254\.)" {
      geoip {
           database => "/opt/logstash/GeoLite2-City.mmdb"
           source => "DestinationIP"
           target => "DestinationIPGeo"
      }
      # Delete 0,0 in DestinationIPGeo.location if equal to 0,0
      if ([DestinationIPGeo.location] and [DestinationIPGeo.location] =~ "0,0") {
        mutate {
          replace => [ "DestinationIPGeo.location", "" ]
        }
      }
    }

  # Takes the 5-tuple of source address, source port, destination address, destination port, and protocol and does a SHA1 hash to fingerprint the flow.  This is a useful
  # way to be able to do top N terms queries on flows, not just on one field.
  if [SourceAddress] and [DestinationAddress] {
    fingerprint {
      concatenate_sources => true
      method => "SHA1"
      key => "logstash"
      source => [ "SourceAddress", "SourcePort", "DestinationAddress", "DestinationPort", "Protocol" ]
    }
  }
} #end filter block

output {
  #stdout { codec => rubydebug }
  #stdout { debug => true }
  elasticsearch {
    index => "traffic"
    hosts => ["localhost:9200"]
    # template => "/opt/logstash/traffic-template.json"
    # template_overwrite => true
  }
} #end output block
